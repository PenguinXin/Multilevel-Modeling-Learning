---
title: "Multilevel Modeling Learning"
date: '`r format(Sys.Date(), "%Y-%m-%d")`'
output:
  html_document:
    code_folding: hide
    theme: flat
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
  pdf_document:
    toc: yes
    toc_depth: '5'
editor_options:
  chunk_output_type: console
---
```{r}
library(tidyverse)
library(lme4)
library(remotes) # installation from remote rep
library(easystats)
library(equatiomatic)
library(here)
library(magrittr)
library(performance)
library(broom.mixed)
library(merTools)
library(ggeffects)
```



```{r}
library(tidyverse)
library(lme4)

library(remotes) # installation from remote rep

remotes::install_github("easystats/easystats")
library(easystats)

remotes::install_github("datalorax/equatiomatic")
library(equatiomatic) # convert model to equations

install.packages("magrittr")
library(magrittr)


```

```{r}
# mean math scores by school
sch_means <- hsb |> 
  group_by(sch.id) |> 
  summarize(sch_mean = mean(math, na.rm = TRUE),
            sch_mean_se = sd(math, na.rm = TRUE) / sqrt(n())) |> 
  ungroup()

# plot the mean by school
sch_means |> 
  mutate(sch.id = factor(sch.id),
         sch.id = reorder(sch.id, sch_mean)) |> 
  ggplot(aes(x = sch_mean, y = sch.id)) +
  geom_point(color = "#0aadff") +
  # add se of mean as error bar
  geom_errorbarh(
    aes(xmin = sch_mean - 1.96*sch_mean_se,
        xmax = sch_mean + 1.96*sch_mean_se)
  ) +
  # add sample mean
  geom_vline(xintercept = mean(hsb$math, na.rm = TRUE),
             color = "#0affa5", linewidth = 2)

```

Is there between-school variation in math scores?
Fit an unconditional model where we fit an intercept and allow that intercept to vary by school
Every school will get its own estimated mean
The intercept will represent its overall mean and the random effect is the deviation from that overall mean

An unconditional model just estimates a mean score for each school
If we have no other variables in our model, the prediction for each student would equal the school mean
```{r}
# fit a basic model
library(lme4)

# unconditional model

# outcome variable predicted by the intercept and the intercept variation by school
m0 <- lmer(math ~ 1 + (1|sch.id), hsb) # 1 means intercept; paranthesis defines random effect
summary(m0)
```

One fixed effect is the intercept
On average, students scored 12.637 on their math assessment
That average varied between school with a SD of 2.935

```{r}
# pull estimated means
estimated_means <- coef(m0)$sch.id

# merge it with the original dataset
estimated_means <- estimated_means %>% 
  mutate(sch.id = as.integer(rownames(.))) %>% 
  rename(intercept = `(Intercept)`)

left_join(sch_means, estimated_means) %>% 
  mutate(sch.id = factor(sch.id),
         sch.id = reorder(sch.id, sch_mean)) %>% 
  ggplot(aes(sch_mean, sch.id)) +
  geom_point(color = "#0aadff") +
  geom_point(aes(x = intercept),
             color = "#ff0ad6") +
    geom_vline(xintercept = mean(hsb$math, na.rm = TRUE),
             color = "#0affa5",
             size = 2)
```

```{r}
# estimate ICC
library(performance)

icc(m0)
```

Approximately 18% of the variability in math scores lies between schools

# Data structuring and basic models
```{r}
library(here)
library(tidyverse)

curran <- read_csv(here("curran.csv"))
```

The data are a sample of 405 children.
Four repeated measures of both the child's antisocial behavior and the child's reading recognition skills
emotional support and cognitive stimulation provided by the mother were collected on the first measurement occasion

reading scores as the outcome

Make the data longer
```{r}
read <- curran %>% 
  select(id, starts_with("read"))
read %>% 
  pivot_longer(
    cols = read1:read4,
    names_to = "timepoint",
    values_to = "score"
  )
# alternative
read %>% 
  pivot_longer(-id,
               names_to = "timepoint",
               values_to = "score")

```


Change timepoint to 0, 1, 2, 3; 0 is the one where you want the intercept to be

We want to fit a growth model. It means timepoints need to be numeric
```{r}
read %>% 
  pivot_longer(-id,
               names_to = "timepoint",
               values_to = "score") %>% 
  mutate(timepoint = parse_number(timepoint) - 1) 

# OR transform during the pivot
sub1 <- function(x) parse_number(x) - 1
read %>% 
  pivot_longer(-id,
               names_to = "timepoint",
               values_to = "score",
               names_transform = list(
                 timepoint = sub1)
               )

# create a long data object and transform it to wide format
l <- read %>% 
  pivot_longer(-id,
               names_to = "timepoint",
               values_to = "score",
               names_transform = list(
                 timepoint = sub1)
               )

l %>% 
  pivot_wider(
    names_from = timepoint,
    values_from = score
  )
```

```{r}
d <- curran %>% 
  pivot_longer(c(starts_with("read"), starts_with("anti")),
               names_to = "variable",
               values_to = "score") %>% 
  mutate(timepoint = parse_number(variable) - 1,
         variable = str_sub(variable, start = 1, end = 4)) %>%  # pull the first 4 characters
  pivot_wider(
    names_from = variable,
    values_from = score
  )

d
```

Another example
```{r}
ls <- read_csv(here("ls19.csv"))
```

# Unconditional growth model

Let's first fit a model with random intercepts
Forcing everyone to grow at the same rate (fixed slope)
```{r}
library(lme4)
m_intercepts <- lmer(read ~ 1 + timepoint + (1|id),
                     data = d) # 1 is intercept, timepoint column which is a predictor; the parenthesis specifies random effect; intercept varies randomly across id 

summary(m_intercepts)


```

In this model, each student gets their own intercept but the slope is constrained to be the same for every one
We allow each student to have a different starting point, but constrain the rate of change to be constant
How reasonable is this assumption?

Yes, this is a reasonable assumption. A parsimonious model

Model summary interpretation:

Below Fixed effects:
(Intercept) estimate = 2.70 is the value when the predictor(timepoint) is zero; Kids on average has a reading score of 2.7 when they started in the study
timepoint estimate = 1.10; they grew on average about 1.1 on the reading recognition per timepoint (assume all students grew at 1.1; no student variation at the slope )

Below Random effects:
405 participants with 1325 observations
id (Intercept) Std. Dev = 0.8830; the score of 2.70 varies between students with a sd of 0.883
Residual std. Dev = 0.6789; our model prediction is off by a sd of 0.6789 (the distribution of the error has a sd of 0.6789)

# Random slopes
Let's fit a second model that allows each participant to have a different slope
```{r}
m_slopes <- lmer(read ~ 1 + timepoint + (1 + timepoint|id), data = d)
m_slopes <- lmer(read ~ 1 + timepoint + (timepoint|id), data = d) # these two are the same; intercepts are generally implied
# 1+timepoint are randomly varying across id; I want not only the intercept but also the timepoint to randomly vary across id

summary(m_slopes)
```

You are not only estimating an additional variance component (variance of the intercept and variance of the slope), but also the covariance among them

Model summary interpretation:
Below Fixed effects:
(Intercept) estimate = 2.696; students start with an average 2.696 on reading recognition score; it varies between students with a sd of 0.757 (from Random effects, id, intercept, Std. Dev)
timepoint estimate = 1.119; students grew on average 1.119 per timepoint. That varies between students with a sd of 0.2731 (from Rnadom effects, timepoint, Std. Dev)

Below Random effects:
Corr 0.29; between intercept and slope; students who started higher had a higher growth 

The lme4 package does not report p-values. Because it's not straightforward to calculate the denominator degress of freedom for an F test
The methods that are used are approximations and, although generally accepted, are not guaranteed to be correct

Interpret the confidence intervals or use the approximation that others use via {lmerTest} package

```{r}
# profiled confidence intervals
confint(m_slopes) # takes a while 

```

It doesn't tell you the random effects. Need to match them up (look at the Random effects, Std. Dev. and Corr)

The gold standard is to use bootstrap confidence intervals. But most of the time, profiles and bootstrap confidence intervals are very similar

```{r}
library(lmerTest)

# refit model
m_slopes2 <- lmer(read ~ timepoint + (timepoint|id), data = d)
summary(m_slopes2)

```

Comparing models
How do we know which model is preferred?
- chi-square significance test of the change in the model deviance
- information criteria like AIC, BIC
- cross-validation procedures

```{r}
# using the built-in approach
anova(m_intercepts, m_slopes)
```

When p value < .05, it means it's very unlikely the chi-square change is due to chance

{performance} package has similar information but nicer output
```{r}
library(performance)
compare_performance(m_intercepts, m_slopes) %>% 
  print_md()

# or use Bayes factors; This is the default if the models are nested
test_performance(m_intercepts, m_slopes) %>% 
  print_md()

```

Bayes factors test under which model the observed data are more likely

# Predictions Model Visualizations
Fit each of the following models
1. popular as the outcome, with a random intercept for class
2. popular as the outcome, with sex included as a fixed effect and a random intercept for class
3. popular as the outcome, with sex included as a fixed effect and a random intercept and slope for class
```{r}
# popular <- read_csv(here("Multilevel-Modeling-Learning", "popularity.csv"))
popular <- read_csv(here("popularity.csv"))
# the unconditional model
m0 <- lmer(popular ~ 1 + (1|class), data = popular) # random intercept for class = intercept varies across class
m1 <- lmer(popular ~ sex + (1|class), data = popular) # sex as a fixed effect
m2 <- lmer(popular ~ sex + (sex|class), data = popular)

# compare performance
compare_performance(m0, m1, m2) %>% print_md()

test_likelihoodratio(m0, m1) %>% 
  print_md()

test_likelihoodratio(m1, m2) %>% 
  print_md()
```

Coefficient plots
{parameters} package
{broom.mixed} package
```{r}
install.packages("broom.mixed") # tidying mixed model
library(broom.mixed)

tidy(m0)
# get just the fixed effects
tidy(m0, effects = "fixed")

# let's tidy all three models, extracting just the fixed effects, and adding in a 95% confidence interval
models <- bind_rows(
  tidy(m0, effects = "fixed", conf.int = TRUE),
  tidy(m1, effects = "fixed", conf.int = TRUE),
  tidy(m2, effects = "fixed", conf.int = TRUE),
  .id = "model"
) %>% 
  mutate(model = as.numeric(model) - 1)

pd <- position_dodge(0.5)

models %>%
  ggplot(aes(estimate, term, color = factor(model))) +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high),
                 position = pd,
                 height = 0.2) +
  geom_point(position = pd)

### using parameters package to visualize
library(parameters)

models2 <- bind_rows(
  as_tibble(parameters(m0)),
  as_tibble(parameters(m1)),
  as_tibble(parameters(m2)),
  .id = "model"
) %>% 
  mutate(model = as.numeric(model) - 1)


```

```{r}
# variance components
# using bootstrap or profiled CIs
tidy(m0, effects = "ran_pars", conf.int = TRUE, conf.method = "boot")
tidy(m2, effects = "ran_pars", conf.int = TRUE, conf.method = "boot")

pull_model_results <- function(model) {
  tidy(
    model,
    conf.int = TRUE,
    conf.method = "boot"
  )
}

full_models <- bind_rows(
  pull_model_results(m0),
  pull_model_results(m1),
  pull_model_results(m2),
  .id = "model"
)

full_models %>% 
  ggplot(aes(estimate, term, color = factor(model))) +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high),
                 position = pd,
                 height = 0.2) +
  geom_point(position = pd) +
  facet_wrap(~ effect, scales = "free_y") +
  theme(legend.position = "bottom")

tidy(m0, effects = "ran_vals") # ran_vals are centered around zero
tidy(m0, effects = "ran_coefs") # ran_coefs provide the class-level predictions; the intercept + the estimated ran_vals

# the same
tidy(m0, effects = "ran_vals")$estimate[1:5] + fixef(m0)[1]
tidy(m0, effects = "ran_coefs")$estimate[1:5]

# plot the ran_vals
m0_ranvals <- tidy(m0, effects = "ran_vals", conf.int = TRUE)

m0_ranvals %>% 
  mutate(level = reorder(factor(level), estimate)) %>% 
  ggplot(aes(level, estimate)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high),
                width = 0.2) +
  geom_point() +
  geom_hline(yintercept = 0, size = 2, color = "magenta")
```

Making predictions "by hand"

```{r}
# a standard regression
m <- lm(popular ~  1 + sex, data = popular) # 1 can be omitted

# make a prediction for the first student
pupil1 <- popular[1, ]
pupil1

coef(m)[1] + # intercept
  coef(m)[2] * (pupil1$sex == "girl")

predict(m)[1]

# multilevel model
predict(m2)[1]

m2
tidy(m2)
```

When we have classroom random effects for the intercept and slope,
the prediction for an individual is made up of:
overall intercept + overall slope +
classroom intercept offset (diff of classroom intercept from overall intercept) +
classroom slope offset (diff of classroom slope from overall slope)

```{r}
m2_ranvals <- tidy(m2, effects = "ran_vals")
class1_ranvals <- m2_ranvals %>% 
  filter(group == "class", level == 1)

tidy(m2, effects = "fixed")

fixef(m2)[1] + fixef(m2)[2] * (popular[1, ]$sex == "girl") + class1_ranvals$estimate[1] + class1_ranvals$estimate[2]

predict(m2)[1]

# calculate the predicted score for a boy in classroom 10 from m2
class10_ranvals <- m2_ranvals %>% 
  filter(group == "class", level == 10)

fixef(m2)[1] + class10_ranvals$estimate[1]

# confirm
test <- popular %>% 
  mutate(pred = predict(m2)) %>% 
  filter(class == 10, sex == "boy")
test
```

Another example
Fit a model with wave and treatment as predictors of students' score.
Allow the intercept and the relation between wave and score to vary by student

```{r}
library(equatiomatic)
dim(sim_longitudinal)

m <- lmer(score ~ wave + treatment + (wave|sid), data = sim_longitudinal) # wave random varied across student id

# limit our data to the first three students
first_three <- sim_longitudinal %>% 
  ungroup() %>% 
  filter(sid %in% 1:3)


first_three %>% 
  mutate(model_pred = predict(m, newdata = first_three)) %>% 
  ggplot(aes(wave, score, color = treatment)) +
  geom_point() +
  geom_line() +
  geom_line(aes(y = model_pred)) +
  facet_wrap(~sid)

# make a prediction outside our data
# student 2 has a considerably lower intercept;
# what would we predict the trend would look like if they had been in the treatment group

a_new_one <- first_three %>% 
  filter(sid == 2) %>% 
  mutate(treatment = 1,
         treatment = as.factor(treatment))

a_new_one %>% 
  mutate(model_pred = predict(m, newdata = a_new_one)) %>% 
  ggplot(aes(wave, score)) +
  geom_point() +
  geom_line() +
  geom_line(aes(y = model_pred))

###
stu2_trt <- data.frame(
  sid = 2,
  wave = 0:9,
  treatment = factor("1", levels = c(0, 1))
)

predict(m, newdata = stu2_trt)

sim_longitudinal %>% 
  filter(sid == 2) %>% 
  mutate(model_pred = predict(m, newdata = .),
         trt_pred = predict(m, newdata = stu2_trt)) %>% 
  ggplot(aes(wave, score)) +
  geom_point() +
  geom_line() +
  geom_line(aes(y = model_pred)) +
  geom_line(aes(y = trt_pred), color = "firebrick") +
  annotate(
    "text",
    x = 6, y = 81, hjust = 0, 
    color = "firebrick",
    label = "Predicted slope if student/nwas in treatment group"
  )
```

Uncertainty
We want to predict what time points 10, 11, and 12 would look like for the first three students
```{r}
pred_frame <- data.frame(
  sid = rep(1:3, each = 13),
  wave = rep(0:12),
  treatment = factor(rep(c(1, 0, 1), each = 13))
)

install.packages("merTools")
library(merTools)

# create a prediction interval with predictInterval(), using simulation to obtain the prediction interval
m_pred_interval <- predictInterval(
  m,
  newdata = pred_frame,
  level = 0.95
)

bind_cols(pred_frame, m_pred_interval) %>% 
  ggplot(aes(wave, fit)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr),
              alpha = 0.4) +
  geom_line(color = "magenta") +
  facet_wrap(~sid)

# write a function to compute the predictions for each bootstrap resample
pred_fun <- function(fit) {
  predict(fit, newdata = pred_frame)
}

# create bootstrapping estimates
b <- bootMer(
  m,
  nsim = 1000,
  FUN = pred_fun,
  use.u = TRUE,
  seed = 42
)

bd <- as.data.frame(t(b$t)) %>% 
  mutate(sid = rep(1:3, each = 13),
         wave = rep(0:12, 3)) %>% 
  pivot_longer(
    starts_with("V"),
    names_to = "bootstrap_sample",
    names_prefix = "V",
    names_transform = list(bootstrap_sample = as.numeric),
    values_to = "score"
  ) %>% 
  arrange(sid, bootstrap_sample, wave)

ggplot(bd, aes(wave, score)) +
  geom_line(aes(group = bootstrap_sample),
            size = 0.1,
            alpha = 0.5,
            color = "cornflowerblue") +
  facet_wrap(~sid)

bd_ribbons <- bd %>% 
  group_by(sid, wave) %>% 
  summarize(quantile = quantile(score, c(0.025, 0.975)),
            group = c("lower", "upper")) %>% 
  pivot_wider(names_from = "group", values_from = "quantile")

bd_ribbons <- left_join(first_three, bd_ribbons) %>% 
  mutate(pred = predict(m, newdata = first_three))

ggplot(bd_ribbons, aes(wave, score)) +
  geom_ribbon(aes(ymin = lower, ymax = upper),
              alpha = 0.5) +
  geom_line(aes(y = pred), size = 1, color = "magenta") +
  geom_point() +
  facet_wrap(~sid)
```

Create an interaction between treatment and wave
The relationship between wave and score is different for each treatment - the steepness of the slope is different across each treatment group
Also add in a school-level random effect for the intercept

```{r}
# implicit nesting
# the student ids are unique
m1a <- lmer(score ~ wave*treatment + (wave|sid) + (1|school),
            data = sim_longitudinal)

# explicit nesting
# students ids are not unique; student 1-5 in school 1 and student 1-5 in school 2
m1b <- lmer(score ~ wave*treatment + (wave|sid:school) + (1|school),
            data = sim_longitudinal)

```

How does a three-level model differ from a two-level model in terms of model predictions?

```{r}
# make a prediction for the first student at the fourth time point
sim_longitudinal[4, ]

fixed <- fixef(m1a)
ranefs <- ranef(m1a)

# pull just the ranefs for sid 1 and school 1
sid_ranefs <- ranefs$sid[1, ]
sch_ranefs <- ranefs$school[1, ]

(fixed[1] + sid_ranefs[1] + sch_ranefs) + # intercept
((fixed[2] + sid_ranefs[2]) * 3) + # fourth timepoint
(fixed[3] * 1) + # treatment effect
(fixed[4] * 3) # treatment by wave effect

# confirm
predict(m1a, newdata = sim_longitudinal[4, ])
```

Let's randomly sample 5 students in the first 4 school and display the model predictions for those students
```{r}
samp <- sim_longitudinal %>% 
  filter(school %in% 1:4) %>% 
  group_by(school, sid) %>% 
  nest()

set.seed(42)

samp <- samp %>% 
  group_by(school) %>% 
  sample_n(5) %>% 
  unnest(data) %>% 
  ungroup()

samp %>% 
  mutate(pred = predict(m1a, newdata = samp)) %>% 
  ggplot(aes(wave, pred, group = sid)) +
  geom_line() +
  facet_wrap(~ school)
```

Marginal effect
A marginal effect shows the relation between one variable in the model and the outcome, while averaging over the other predictors in the model
```{r}
m2 <- lmer(score ~ wave*treatment + group + prop_low + (wave|sid) + (1|school),
           data = sim_longitudinal)

summary(m2)
```

Let's look at the relation between wave and score by treatment, holding the other values constant

```{r}
# build a prediction data frame
# we'll make population-level prediction - i.e., ignoring the random effects
marginal_frame1 <- data.frame(
  wave = rep(0:9, 2),
  treatment = as.factor(rep(c(0, 1), each = 10)),
  group = factor("high", levels = c("low", "medium", "high")),
  prop_low = mean(sim_longitudinal$prop_low, na.rm = TRUE),
  sid = -999,
  school = -999
)

marginal_frame1 <- marginal_frame1 %>% 
  mutate(pred = predict(m2,
                        newdata = marginal_frame1,
                        allow.new.levels = TRUE)) # just using the fixed effects to make predictions

marginal_frame1 %>% 
  ggplot(aes(wave, pred, color = treatment)) +
  geom_line()

# automated method
install.packages("ggeffects")
library(ggeffects)

ggpredict(m2, "wave")
ggpredict(m2, c("wave", "treatment")) %>% 
  plot()

ggpredict(m2, c("wave", "treatment", "group"),
          condition = c(sid = 1, school = 1))
```


